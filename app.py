import streamlit as st
import google.generativeai as genai

# --- C·∫§U H√åNH TRANG WEB ---
st.set_page_config(
    page_title="My AI App",
    page_icon="ü§ñ",
    layout="centered"
)

st.title("ü§ñ Tr·ª£ l√Ω AI c·ªßa t√¥i")

# --- L·∫§Y API KEY T·ª™ H·ªÜ TH·ªêNG B·∫¢O M·∫¨T ---
# ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t key trong Streamlit Secrets
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y API Key. H√£y c·∫•u h√¨nh trong ph·∫ßn Secrets c·ªßa Streamlit.")
    st.stop()

genai.configure(api_key=api_key)

# --- C·∫§U H√åNH M√î H√åNH (QUAN TR·ªåNG) ---
# 1. B·∫°n h√£y copy n·ªôi dung 'System Instructions' trong Google AI Studio
# 2. D√°n ƒë√® v√†o ƒëo·∫°n vƒÉn b·∫£n gi·ªØa 3 d·∫•u nh√°y k√©p b√™n d∆∞·ªõi
SYSTEM_PROMPT = """
App b√°o gi√° n·ªôi th·∫•t th√¥ng minh d·ª±a tr√™n h√¨nh ·∫£nh
"""

# C·∫•u h√¨nh tham s·ªë sinh vƒÉn b·∫£n (gi·ªëng b√™n ph·∫£i m√†n h√¨nh AI Studio)
generation_config = {
  "temperature": 1,
  "top_p": 0.95,
  "top_k": 64,
  "max_output_tokens": 8192,
}

# Kh·ªüi t·∫°o Model
@st.cache_resource
def load_model():
    return genai.GenerativeModel(
        model_name="gemini-1.5-flash", # Ho·∫∑c "gemini-1.5-pro" t√πy b·∫°n ch·ªçn
        generation_config=generation_config,
        system_instruction=SYSTEM_PROMPT
    )

model = load_model()

# --- X·ª¨ L√ù L·ªäCH S·ª¨ CHAT ---
# Kh·ªüi t·∫°o l·ªãch s·ª≠ n·∫øu ch∆∞a c√≥
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·∫°i c√°c tin nh·∫Øn c≈© tr√™n m√†n h√¨nh
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- X·ª¨ L√ù KHI NG∆Ø·ªúI D√ôNG NH·∫¨P LI·ªÜU ---
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n ·ªü ƒë√¢y..."):
    # 1. Hi·ªÉn th·ªã c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
    with st.chat_message("user"):
        st.markdown(prompt)
    # L∆∞u v√†o l·ªãch s·ª≠
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. G·ª≠i qua Google Gemini ƒë·ªÉ l·∫•y c√¢u tr·∫£ l·ªùi
    try:
        # T·∫°o phi√™n chat m·ªõi v·ªõi l·ªãch s·ª≠ c≈©
        chat_history = [
            {"role": "user" if msg["role"] == "user" else "model", "parts": [msg["content"]]} 
            for msg in st.session_state.messages[:-1] # L·∫•y t·∫•t c·∫£ tr·ª´ c√¢u m·ªõi nh·∫•t v·ª´a nh·∫≠p
        ]
        
        chat = model.start_chat(history=chat_history)
        response = chat.send_message(prompt)

        # 3. Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi c·ªßa AI
        with st.chat_message("assistant"):
            st.markdown(response.text)
        
        # L∆∞u c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠
        st.session_state.messages.append({"role": "assistant", "content": response.text})

    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
